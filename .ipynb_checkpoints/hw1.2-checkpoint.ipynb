{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import MNIST\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "mndata = MNIST('data/mnist_data_files')\n",
    "mndata.gz=True\n",
    "train_images, train_labels = mndata.load_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "# 60000 rows 28*28 pixels\n",
    "print(train_images.shape) \n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = pd.Series(train_labels).value_counts(normalize=True)\n",
    "indices = np.asarray(value_counts.index.values)\n",
    "value_counts = np.asarray(value_counts)\n",
    "p_train_labels = np.vstack([indices, value_counts]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.11236667]\n",
      " [7.         0.10441667]\n",
      " [3.         0.10218333]\n",
      " [2.         0.0993    ]\n",
      " [9.         0.09915   ]\n",
      " [0.         0.09871667]\n",
      " [6.         0.09863333]\n",
      " [8.         0.09751667]\n",
      " [4.         0.09736667]\n",
      " [5.         0.09035   ]]\n"
     ]
    }
   ],
   "source": [
    "print(p_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images, test_labels = mndata.load_testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "[2 1 0 4 1 4 9 5 9]\n"
     ]
    }
   ],
   "source": [
    "print(test_images.shape)\n",
    "print(test_labels[1:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes - normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = np.apply_along_axis(lambda x: norm.fit(x), 1, train_images.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_likelihood_for_each_label(p_label, feature_vec, params):\n",
    "    means = params.T[0]\n",
    "    variations = params.T[1]\n",
    "    likelihood = np.nansum(norm.logpdf(feature_vec, means, np.sqrt(variations)))\n",
    "    likelihood = likelihood + np.log(p_label[1])\n",
    "    return np.array([p_label[0], likelihood])\n",
    "    \n",
    "def get_predict(likelihoods):\n",
    "    max_row = [float(\"-inf\"), float(\"-inf\")]\n",
    "    for likelihood in likelihoods:\n",
    "        if(likelihood[1] > max_row[1]):\n",
    "            max_row = likelihood\n",
    "    return max_row[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_image):\n",
    "    likelihoods = np.apply_along_axis(lambda label: calculate_likelihood_for_each_label(label, test_image, params), 1, p_train_labels)\n",
    "    return get_predict(likelihoods)\n",
    "    \n",
    "predicts = np.apply_along_axis(lambda image: predict(image), 1, test_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(actual, predicts):\n",
    "    TP = 0\n",
    "    num_total = len(actual)\n",
    "    for i in range(num_total):\n",
    "        if actual[i] == predicts[i]:\n",
    "            TP = TP + 1\n",
    "    return TP/num_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1135"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_accuracy(test_labels, predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
